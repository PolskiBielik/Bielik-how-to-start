{
  "cells": [
    {
      "metadata": {
        "id": "b315ecd49bdab447"
      },
      "cell_type": "markdown",
      "source": [
        "# Bielik + Ollama – czyli proste uruchomienie LLM"
      ],
      "id": "b315ecd49bdab447"
    },
    {
      "metadata": {
        "id": "7eae5e1055075fd"
      },
      "cell_type": "markdown",
      "source": [
        "LLM można używać bezpośrednio korzystając z biblioteki **transformers** od HuggigFace, lecz na dłuższą metę może okazać się to uciążliwe – np. trzymanie modelu w obiektach i zarządzanie nimi (często powiązane z obsługą GPU).\n",
        "\n",
        "Z pomocą przychodzą różne narzędzia takie jak: **Ollama**, **vLLM**, **Text Generation Interface (TGI)** czy **llama.cpp** – w tym tutorialu ze względu na prostotę zostanie omówione pierwsze rozwiązanie."
      ],
      "id": "7eae5e1055075fd"
    },
    {
      "metadata": {
        "id": "a294d7a06f0f8712"
      },
      "cell_type": "markdown",
      "source": [
        "## Ollama\n",
        "\n",
        "Ollama to narzędzie do uruchamiania i zarządzania dużymi modelami językowymi na lokalnym komputerze. Zapewnia prosty interfejs do korzystania z gotowych modeli, jak również możliwość ich personalizacji i dostosowywania za pomocą specjalnych plików konfiguracyjnych. Ollama jest dostępna na różnych platformach, w tym macOS, Windows oraz Linux.\n",
        "\n",
        "Przydatne linki:\n",
        "  - Oficjalna strona projektu: https://ollama.com\n",
        "  - Github: https://github.com/ollama/ollama\n",
        "  - Dokumentacja API: https://github.com/ollama/ollama/blob/main/docs/api.md"
      ],
      "id": "a294d7a06f0f8712"
    },
    {
      "metadata": {
        "id": "31033784729db073"
      },
      "cell_type": "markdown",
      "source": [
        "### Ollama instalacja\n",
        "\n",
        "Narzędzie jest wspierana na platformach macOS, Windows oraz Linux. Należy zainstalować ją jako klasyczną aplikację. Na platformach Windows i macOS będzie to możliwe poprzez klasyczne pobranie z zainstalowanie pakietu, natomiast dla Linux będzie trzeba odpalić specjalną komendę *[stan na sierpień 2024]*.\n",
        "\n",
        "Szczegółowe informacje znajdują się na stronie projektu.\n",
        "\n",
        "Aplikacja działa w oparciu o Command Line Interface (CLI) – wiersz poleceń. W celu weryfikacji poprawnej instalacji zalecam uruchomienie komendy: `ollama`. Jako wynik powinno pokazać się wynik przedstawiony poniżej (dokładnie instrukcja tego narzędzia). Jeśli pojawią się błędy to znaczy że narzędzie nie zostało zainstalowane poprawnie.\n",
        "\n",
        "```shell\n",
        "(base) sample_user@MacBook-Pro SPEAKLEASH % ollama\n",
        "Large language model runner\n",
        "\n",
        "Usage:\n",
        "  ollama [flags]\n",
        "  ollama [command]\n",
        "\n",
        "Available Commands:\n",
        "  serve       Start ollama\n",
        "  create      Create a model from a Modelfile\n",
        "  show        Show information for a model\n",
        "  run         Run a model\n",
        "  pull        Pull a model from a registry\n",
        "  push        Push a model to a registry\n",
        "  list        List models\n",
        "  ps          List running models\n",
        "  cp          Copy a model\n",
        "  rm          Remove a model\n",
        "  help        Help about any command\n",
        "\n",
        "Flags:\n",
        "  -h, --help      help for ollama\n",
        "  -v, --version   Show version information\n",
        "\n",
        "Use \"ollama [command] --help\" for more information about a command.\n",
        "```"
      ],
      "id": "31033784729db073"
    },
    {
      "metadata": {
        "id": "9fe1a72a6ffada73"
      },
      "cell_type": "markdown",
      "source": [
        "### Ollama uruchomienie poprzez CLI\n",
        "\n",
        "Aby uruchomić LLM należy wpisać komendę:\n",
        "\n",
        "```shell\n",
        "ollama run SpeakLeash/bielik-7b-instruct-v0.1-gguf\n",
        "```\n",
        "\n",
        "Za pierwszym razem model będzie się pobierać na komputer co może potrwać dłuższą chwilę.\n",
        "Po poprawnym załadowaniu będzie można zacząć korzystać z modelu w konsoli.\n",
        "\n",
        "```shell\n",
        "(base) marcinwatroba@DataScienceServer:~$ ollama run SpeakLeash/bielik-7b-instruct-v0.1-gguf\n",
        ">>> Ile to jest 2+4?\n",
        "<s>  2 plus 4 równa się 6.\n",
        "\n",
        ">>> Kto napisał Pana Tadeusza?\n",
        "<s>  Adam Mickiewicz napisał \"Pana Tadeusza\".\n",
        "\n",
        ">>>\n",
        "```"
      ],
      "id": "9fe1a72a6ffada73"
    },
    {
      "metadata": {
        "id": "cc59aec5b7383d70"
      },
      "cell_type": "markdown",
      "source": [
        "### Ollama – korzystanie z API (curl)\n",
        "\n",
        "Ollama poza korzystaniem z CLI udostępnia również możliwość komunikacji poprzez Rest API.\n",
        "Pozwala to na korzystanie z modelu w praktycznie każdej aplikacji, co daje całkiem spore możliwości.\n",
        "\n",
        "Domyślnie aplikacja działa na porcie 11434. Oznacza to że jej domyślny host to http://localhost:11434 i z niego będziemy korzystać w poniższych przykładach.\n",
        "\n",
        "Najprostszym przykładem będzie po prostu uruchomienie klasycznego zapytania dla zapytania składającego się z listy wiadomości (szczegóły dotyczące API znajdują się pod adresem https://github.com/ollama/ollama/blob/main/docs/api.md).\n",
        "\n",
        "Poniżej znajduje się polecenie zapytanie w popularnej bibliotece curl -- można jej używać w formie CLI (bez większych umiejętności programowania)"
      ],
      "id": "cc59aec5b7383d70"
    },
    {
      "metadata": {
        "id": "83761122309b676a"
      },
      "cell_type": "markdown",
      "source": [
        "```shell\n",
        "curl http://localhost:11434/api/chat -d '{\n",
        "  \"model\": \"SpeakLeash/bielik-7b-instruct-v0.1-gguf\",\n",
        "  \"stream\": false,\n",
        "  \"messages\": [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Odpowiedz krótko na pytanie\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Kim jest Adam Mickiewicz?\"\n",
        "    }\n",
        "  ]\n",
        "}'\n",
        "```\n",
        "\n",
        "Zapytanie ma body w formie JSON, gdzie istotne są 3 parametry: `model`, `stream` i `messages`.\n",
        "W odpowiedzi otrzymany następująxcy obiekt:\n",
        "```\n",
        "{\n",
        "   \"model\":\"SpeakLeash/bielik-7b-instruct-v0.1-gguf\",\n",
        "   \"created_at\":\"2024-08-21T15:45:22.580717683Z\",\n",
        "   \"message\":{\n",
        "      \"role\":\"assistant\",\n",
        "      \"content\":\"\\u003cs\\u003e  Adam Mickiewicz to polski poeta, uważany za jednego z najważniejszych twórców literatury romantyzmu. Znany m.in. z dzieł \\\"Pan Tadeusz\\\" i \\\"Dziady\\\".\"\n",
        "   },\n",
        "   \"done_reason\":\"stop\",\n",
        "   \"done\":true,\n",
        "   \"total_duration\":967596312,\n",
        "   \"load_duration\":4041118,\n",
        "   \"prompt_eval_count\":44,\n",
        "   \"prompt_eval_duration\":34273000,\n",
        "   \"eval_count\":65,\n",
        "   \"eval_duration\":798981000\n",
        "}\n",
        "```"
      ],
      "id": "83761122309b676a"
    },
    {
      "metadata": {
        "id": "a5a2bc26b1644f82"
      },
      "cell_type": "markdown",
      "source": [
        "### Ollama – korzystanie z API (python)\n",
        "\n",
        "Analogiczny przykład z powyższego zapytania można wykonać w środowisku python.\n",
        "W tym celu należy zainstalować wymagane zależności oraz napisać kod jaki będzie wykonywał zapytanie.\n",
        "\n",
        "Poniżej znajduje się skrypt instalujący biblioteki `httpx` i `requests`. Są one alternatywne i dają takie same funkcjonalności -- jeśli nie znasz żadnej wybierz `httpx`."
      ],
      "id": "a5a2bc26b1644f82"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-21T18:30:14.753392Z",
          "start_time": "2024-08-21T18:30:13.801374Z"
        },
        "id": "97cbdb10e1baf998"
      },
      "cell_type": "code",
      "source": [
        "!pip install -qq httpx requests"
      ],
      "id": "97cbdb10e1baf998",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do celów testowych zastosowano nazwę domeny 'localhost'. Można również zastosować adres IP wskazujący na serwer ollamy."
      ],
      "metadata": {
        "id": "RUtQdy6dKr1Z"
      },
      "id": "RUtQdy6dKr1Z"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-22T15:50:18.718949Z",
          "start_time": "2024-08-22T15:50:18.714712Z"
        },
        "id": "2823dd0e26750b51"
      },
      "cell_type": "code",
      "source": [
        "# pprint jest dodatkowe i można użyć zwykłego print, który nie formatuje składni\n",
        "from pprint import pprint\n",
        "\n",
        "# Stałe dla zapytania — będą tak samo wykorzystane w requests i httpx\n",
        "URL = \"http://localhost:11434/api/chat\"\n",
        "PAYLOAD = {\n",
        "    \"model\": \"SpeakLeash/bielik-7b-instruct-v0.1-gguf\",\n",
        "    \"stream\": False,\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Odpowiedz krótko na pytanie\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Kim jest Adam Mickiewicz?\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "id": "2823dd0e26750b51",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-22T15:50:21.497521Z",
          "start_time": "2024-08-22T15:50:18.722961Z"
        },
        "id": "f3274c4c69c568c6",
        "outputId": "ab93f864-076f-4311-abb8-10765f9eedb4"
      },
      "cell_type": "code",
      "source": [
        "import httpx\n",
        "\n",
        "response = httpx.post(URL, json=PAYLOAD, timeout=500)\n",
        "pprint(response.json())"
      ],
      "id": "f3274c4c69c568c6",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'created_at': '2024-08-22T15:50:21.438020749Z',\n",
            " 'done': True,\n",
            " 'done_reason': 'stop',\n",
            " 'eval_count': 75,\n",
            " 'eval_duration': 646169000,\n",
            " 'load_duration': 1891913891,\n",
            " 'message': {'content': ' Adam Mickiewicz to polski poeta, który brał udział w '\n",
            "                        'powstaniu listopadowym i uważany jest za jednego z '\n",
            "                        'Wieszczów Narodowych. Jego dzieła mocno oddziaływały '\n",
            "                        'na polską kulturę i tożsamość narodową.',\n",
            "             'role': 'assistant'},\n",
            " 'model': 'SpeakLeash/bielik-7b-instruct-v0.1-gguf',\n",
            " 'prompt_eval_count': 41,\n",
            " 'prompt_eval_duration': 20510000,\n",
            " 'total_duration': 2652471217}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-22T15:50:22.210998Z",
          "start_time": "2024-08-22T15:50:21.498729Z"
        },
        "id": "4854db48805c9d42",
        "outputId": "c5ea3b29-7077-4fc3-a2ab-549240cf1bdd"
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.post(URL, json=PAYLOAD)\n",
        "pprint(response.json())"
      ],
      "id": "4854db48805c9d42",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'created_at': '2024-08-22T15:50:22.192379581Z',\n",
            " 'done': True,\n",
            " 'done_reason': 'stop',\n",
            " 'eval_count': 57,\n",
            " 'eval_duration': 488890000,\n",
            " 'load_duration': 4256853,\n",
            " 'message': {'content': ' Adam Mickiewicz to polski poeta, publicysta i '\n",
            "                        'filozof, uważany za jednego z Wieszczów Narodowych. '\n",
            "                        'Jest znany przede wszystkim jako autor epopei \"Pan '\n",
            "                        'Tadeusz\".',\n",
            "             'role': 'assistant'},\n",
            " 'model': 'SpeakLeash/bielik-7b-instruct-v0.1-gguf',\n",
            " 'prompt_eval_count': 41,\n",
            " 'prompt_eval_duration': 8792000,\n",
            " 'total_duration': 646232811}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cd0e10349026b861"
      },
      "cell_type": "markdown",
      "source": [
        "## Podsumowanie\n",
        "\n",
        "Świetnie, w tym tutorialu pokazano jak w podstawowy sposób uruchomić LLM na swoim komputerze. Teraz możesz całkowicie za darmo uruchomić prywatnie LLM i dowolnie z niego korzystać. W przypadku trudniejszych zadań odsyłamy do dokumentacji gdzie będą pokazane bardziej zaawansowane możliwości które z pewnością spełnią bardziej zaawansowane wymagania."
      ],
      "id": "cd0e10349026b861"
    },
    {
      "metadata": {
        "id": "44a307df6032b58d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "44a307df6032b58d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}